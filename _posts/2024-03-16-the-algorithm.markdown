---
layout: post
title: "The Algorithm - No Other Alternative?"
date: 2024-03-16 0:00:00
---

## The Algorithm - No Other Alternative?

Reading [this story](https://www.cbc.ca/news/canada/india-fifth-estate-video-story-1.7142721) about how India asked (and got) YouTube to block an episode by the CBC (Canada's PBS/NPR) about the murder of a Sikh activist in British Columbia.

Two things jumped out at me right away.  First:

> According to one section of that act, the government has the power to
> "intercept, monitor or decrypt any information generated, transmitted,
> received or stored in any computer resource." Such action can be taken,
> according to the act, in the interest of:
> 
> - The sovereignty or integrity of India, defense of India, the security of the state.
> - Friendly relations with foreign states.
> - Public order, or for preventing incitement to the commission of any     
> - cognizable offense relating to these.
> - Investigating any offense.

That is some seriously dystopian shit.  I don't really know what else I can say about that.  In fact, I think I need to go lie down for a minute.

With that out of the way, the other bit which interested me as a person who both creates and uses a lot of software, was the response by YouTube.  They caved, obviously.  Their response, which is effectively, "We are a big boy company, and we have to do this through proper channels.  We'll put our lawyers on it."

As lame a response as this is, it's sortof hard to think of a different strategy.  They *could* tell the Indian government to piss off, that YouTube won't be complicit in the silencing of dissent, especially when it comes to international murder plots.  But that obviously wouldn't work - India would simply ban YouTube, and then YouTube would be out a bunch of money.  So YouTube's basically *only choice* is to fight the case in Indian court.  Which has about a 0 percent chance of success.  Everybody knows this, but nobody would say that, because we have to maintain the illusion that this it the only way things could ever be.

> "There is no alternative" -- Margaret Thatcher

On my list of things to read is Capitalist Realism, by the late Mark Fisher.  The main thrust of the book, as far as I understand, is that in some way we have fallen into a trap, thinking the way our modern economy is structured is "the only option".  

> "Sure! Capitalism is awful, but what other choice do we have? COMMUNISM?!" -- your step-uncle

## Now we get to the algorithm.

Five days after the CBC episode about the guy killed in Canada by the Indian government, this video has just under a quarter of a million views.  Nothing to sneeze at, but it's nothing Earth shaking either.  The problem is there is a risk that the story will go viral. YouTube's recommendation algorithm generates virility.  Let's take a step back and talk about algorithms and AI and stuff for a second.

YouTube's algorithm is astonishingly complex and powerful.  It's proprietary, so we can't tell exactly how it works, but we *do* know that every interaction in the app is monitored and fed into the algorithm.  At it's basic level, we've got:

- What did you search for?
- Did you come to YouTube from an external site?
- Did you watch the video all the way to the end?
- Did you like/comment/subscribe?
- Did you smash that notification bell?

But also much more:

- When scrolling through recommended videos, how long did you pause on the thumbnail before scrolling on?
- Did you click away into another browser tab or mobile app, while the video was running?
- What content are people who are in your area watching?
- YouTube uses a Google account.  What people have you sent emails to? What are they watching?
- What kind of stuff have you searched on Google?  How long did you pause on the google result, before scrolling on?
- Etc.

It's kindof wild to think about, and I wonder about the perspectives of people who were involved in the early days at YouTube.  At its heart, it was simply an effort to keep you using the application.  Keep you watching ads.  It makes sense as a user, too.  According to this ["The State of the Creator Economy" (2022)](https://kstatic.googleusercontent.com/files/721e9ce19a4fe59b40135ad7b06a61d589468bf7df4b2d654c1be32aca225939b6dac1e16d1de1c0d0fe5bb496e82f5920afa7eceb7dc867e4f71751bc233261), over 500 hours of content is uploaded to YouTube each minute. How can you possibly know what to watch?

YouTube figured that if somebody watches a video, watches the whole thing, then it's got something good in there and they should recommend it to other users.  Likewise, if they somehow "interacted" with the video (like/comment/subscribe), then that means they **really** like the video, and YouTube should recommend it to more people.  The end result is that you find more utility in the service, and you're on it for longer and YouTube can sell more advertising.  The longer the CBC video was available online, the higher the risk that it would be identified by YouTube's algorithms as something to display to other users in India, which could spell serious trouble for the Modi regime.

Now we're at the point where YouTube's profit motives are at odds with other forces (the common good).  We're no longer in a "win-win" arrangement, where you serve me ads in exchange for content that will be interesting to me.  YouTube must comply with the Indian government and hide the CBC video.  Not because they can't afford to lose the ability to sell ads that will be displayed to Indian users by defying the Indian government, but because they can't afford to lose the data provided by Indian users.  The thing which generates the virality that the Indian government is afraid of.

## Data is the new gold rush.

It's funny how subtly the goalposts shifted.  Initially, it was a tradeoff - your data for better recommendations.  Better recommendations leading to more time spent on the app.  At some point, there was a realization that what YouTube (and Google, and Facebook, etc) have created was not a "recommendation engine", but rather a "human behavior prediction machine".  The details that YouTube collects about your viewing and browsing habits are combined with the viewing and browsing habits of billions of other people.  All this information, it's used to formulate a prediction, an educated guess: Will you choose this, or that?  This has the potential to take us down some really dark roads.  It also has the potential to make these big internet companies a **lot** of money.  And, that is the reason why YouTube took down the CBC video for Indian audiences.

YouTube is already blocked in China, along with Google, Facebook, Twitter, Instagram, and dozens of others.  China's got a population of close to **1.5 billion people**.  Think of the lost potential in harvested user data.  You know who else has a population close to 1.5 billion?  You guessed it.  With usership in western countries pretty much plateauing, US tech companies have to look South and East.  It would be an absolutely devastating loss to Alphabet if YouTube were shut out of India.  Because their entire business is about generating this user data.

All things being equal, the bigger the dataset, the more accurately you can train your model, your simulation of human behavior.  As these companies get bigger and collect more data, they further cement their position in the technology economy.  You simply cannot create a new search engine in your garage, because to create a search engine that will give good recommendations to users, you need data.  Google has all the data.  Google wants **all** the data.  So they will acquiesce to India's demands, and hide the video about how the Indian government had a Canadian citizen killed, in his own country.

I've kindof run out of steam, writing this up.  I read this article on Wednesday and I'm finally finishing my thoughts about it on Saturday night.  The situation feels pretty bleak because it is.  But Thatcher was wrong.  There are alternatives.  They're just not alternatives that make Alphabet (and their shareholders) the most money possible.  It's said that in a capitalist system, the first priority of a business is to make as much money as possible.  That might be true, but there's a role here for the people to demand their needs be met.  After all, it's **our** economy; we have to live in it.  We can decide, for example, that a service which algorithmically promotes a piece of media has made an editorial decision, and therefore is responsible for it.  Section 230 regulates these services as impartial, neutral platforms, and therefore not held responsible for the content uploaded by their users.  They put their thumb on the scale. Their algorithm suggests content for us, if only to see how we'll react to it.  It plays with us, experiments with us.  Hardly neutral.

